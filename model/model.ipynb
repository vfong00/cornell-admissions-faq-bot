{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincentfong/CS/cornell-admissions-faq-bot/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(token=\"<key redacted>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"faq_processed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Embedded\"] = df[\"Embedded\"].apply(lambda x: client.feature_extraction(x, model=\"sentence-transformers/all-MiniLM-L6-v2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cosine \n",
    "cosines = np.vstack(df[\"Embedded\"])\n",
    "np.save('embeddings.npy', cosines)\n",
    "df.to_pickle(\"faq_with_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Source</th>\n",
       "      <th>Embedded</th>\n",
       "      <th>html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Home &gt; About Cornell &gt; Academics] What is the...</td>\n",
       "      <td>Cornell undergraduates get to know their profe...</td>\n",
       "      <td>https://faq.enrollment.cornell.edu/kb/article/...</td>\n",
       "      <td>[0.0762246, -0.1303518, 0.055723336, 0.0420286...</td>\n",
       "      <td>&lt;div class=\"hf-article_content\"&gt;\\n &lt;p&gt;\\n  &lt;spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Home &gt; About Cornell &gt; Academics] Can I doubl...</td>\n",
       "      <td>Cornell offers nearly 80 majors and more than ...</td>\n",
       "      <td>https://faq.enrollment.cornell.edu/kb/article/...</td>\n",
       "      <td>[0.0745696, -0.0892729, 0.078019045, 0.0002153...</td>\n",
       "      <td>&lt;div class=\"hf-article_content\"&gt;\\n &lt;p&gt;\\n  &lt;spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Home &gt; About Cornell &gt; Academics] Does Cornel...</td>\n",
       "      <td>Several of the academic programs at Cornell of...</td>\n",
       "      <td>https://faq.enrollment.cornell.edu/kb/article/...</td>\n",
       "      <td>[-0.028614562, -0.063003235, 0.052006, -0.0486...</td>\n",
       "      <td>&lt;div class=\"hf-article_content\"&gt;\\n &lt;p&gt;\\n  &lt;spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Home &gt; About Cornell &gt; Academics] What is Cor...</td>\n",
       "      <td>Cornell undergraduates can get to know their p...</td>\n",
       "      <td>https://faq.enrollment.cornell.edu/kb/article/...</td>\n",
       "      <td>[0.04897193, -0.14860685, 0.0192861, -0.001755...</td>\n",
       "      <td>&lt;div class=\"hf-article_content\"&gt;\\n &lt;p&gt;\\n  &lt;spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Home &gt; About Cornell &gt; Academics] How do I ge...</td>\n",
       "      <td>Cornell University’s Courses of Study is publi...</td>\n",
       "      <td>https://faq.enrollment.cornell.edu/kb/article/...</td>\n",
       "      <td>[0.031461887, -0.12976694, 0.012011488, 0.0492...</td>\n",
       "      <td>&lt;div class=\"hf-article_content\"&gt;\\n &lt;p&gt;\\n  &lt;spa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  [Home > About Cornell > Academics] What is the...   \n",
       "1  [Home > About Cornell > Academics] Can I doubl...   \n",
       "2  [Home > About Cornell > Academics] Does Cornel...   \n",
       "3  [Home > About Cornell > Academics] What is Cor...   \n",
       "4  [Home > About Cornell > Academics] How do I ge...   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  Cornell undergraduates get to know their profe...   \n",
       "1  Cornell offers nearly 80 majors and more than ...   \n",
       "2  Several of the academic programs at Cornell of...   \n",
       "3  Cornell undergraduates can get to know their p...   \n",
       "4  Cornell University’s Courses of Study is publi...   \n",
       "\n",
       "                                              Source  \\\n",
       "0  https://faq.enrollment.cornell.edu/kb/article/...   \n",
       "1  https://faq.enrollment.cornell.edu/kb/article/...   \n",
       "2  https://faq.enrollment.cornell.edu/kb/article/...   \n",
       "3  https://faq.enrollment.cornell.edu/kb/article/...   \n",
       "4  https://faq.enrollment.cornell.edu/kb/article/...   \n",
       "\n",
       "                                            Embedded  \\\n",
       "0  [0.0762246, -0.1303518, 0.055723336, 0.0420286...   \n",
       "1  [0.0745696, -0.0892729, 0.078019045, 0.0002153...   \n",
       "2  [-0.028614562, -0.063003235, 0.052006, -0.0486...   \n",
       "3  [0.04897193, -0.14860685, 0.0192861, -0.001755...   \n",
       "4  [0.031461887, -0.12976694, 0.012011488, 0.0492...   \n",
       "\n",
       "                                                html  \n",
       "0  <div class=\"hf-article_content\">\\n <p>\\n  <spa...  \n",
       "1  <div class=\"hf-article_content\">\\n <p>\\n  <spa...  \n",
       "2  <div class=\"hf-article_content\">\\n <p>\\n  <spa...  \n",
       "3  <div class=\"hf-article_content\">\\n <p>\\n  <spa...  \n",
       "4  <div class=\"hf-article_content\">\\n <p>\\n  <spa...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, cosines, df):\n",
    "    query_embedding = client.feature_extraction(query, model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    threshold = 0.5\n",
    "    similarities = cosines@np.array(query_embedding)\n",
    "    sims_above_threshold = np.sum(similarities > threshold)\n",
    "    if sims_above_threshold > 1:\n",
    "        match_idxs = np.argsort(similarities)[-2:][::-1]\n",
    "        prompt = \", \".join([\"[GENERATED ANSWER] \" + df.loc[idx, \"Answer\"] for idx in match_idxs])\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are helping a retrieval system in providing correct answers to the FAQ section of Cornell University's general admissions page. You are given two possible answers, and you should choose and summarize the best one.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    elif sims_above_threshold == 1:\n",
    "        match_idx = np.argmax(similarities)\n",
    "        prompt = df.loc[match_idx, \"Answer\"]\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are helping a retrieval system in providing correct answers to the FAQ section of Cornell University's general admissions page. You are given an answer that you should summarize.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    else:\n",
    "        messages = []\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"Qwen/Qwen2.5-72B-Instruct\", \n",
    "        messages=messages\n",
    "    )\n",
    "    return {\n",
    "        \"Answer\": completion.choices[0].message,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/Qwen/Qwen2.5-72B-Instruct/v1/chat/completions (Request ID: 42IBMX)\n\nModel too busy, unable to get response in less than 120 second(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/CS/cornell-admissions-faq-bot/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/CS/cornell-admissions-faq-bot/.venv/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/Qwen/Qwen2.5-72B-Instruct/v1/chat/completions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhere is Cornell University located?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43msemantic_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcosines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Match:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m, in \u001b[0;36msemantic_search\u001b[0;34m(query, cosines, df)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     messages \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 23\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQwen/Qwen2.5-72B-Instruct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer\u001b[39m\u001b[38;5;124m\"\u001b[39m: completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage,\n\u001b[1;32m     29\u001b[0m }\n",
      "File \u001b[0;32m~/CS/cornell-admissions-faq-bot/.venv/lib/python3.10/site-packages/huggingface_hub/inference/_client.py:970\u001b[0m, in \u001b[0;36mInferenceClient.chat_completion\u001b[0;34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p)\u001b[0m\n\u001b[1;32m    943\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: payload_model,\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m    962\u001b[0m }\n\u001b[1;32m    963\u001b[0m request_parameters \u001b[38;5;241m=\u001b[39m provider_helper\u001b[38;5;241m.\u001b[39mprepare_request(\n\u001b[1;32m    964\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m    965\u001b[0m     parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    968\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[1;32m    969\u001b[0m )\n\u001b[0;32m--> 970\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inner_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _stream_chat_completion_response(data)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/CS/cornell-admissions-faq-bot/.venv/lib/python3.10/site-packages/huggingface_hub/inference/_client.py:327\u001b[0m, in \u001b[0;36mInferenceClient._inner_post\u001b[0;34m(self, request_parameters, stream)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest_parameters\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m~/CS/cornell-admissions-faq-bot/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:477\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 477\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://api-inference.huggingface.co/models/Qwen/Qwen2.5-72B-Instruct/v1/chat/completions (Request ID: 42IBMX)\n\nModel too busy, unable to get response in less than 120 second(s)"
     ]
    }
   ],
   "source": [
    "user_query = \"Where is Cornell University located?\"\n",
    "result = semantic_search(user_query, cosines, df)\n",
    "print(\"Best Match:\")\n",
    "print(f\"Answer: {result['Answer'].content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
